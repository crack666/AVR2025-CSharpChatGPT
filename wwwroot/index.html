<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Voice Chat Assistant</title>
  <style>
    :root {
      --primary-color: #0078d7;
      --secondary-color: #005a9e;
      --bg-color: #f5f5f5;
      --chat-bg: #ffffff;
      --user-bubble: #dcf8c6;
      --bot-bubble: #e8f1f3;
      --border-radius: 10px;
    }
    
    body { 
      font-family: 'Segoe UI', Arial, sans-serif; 
      margin: 0;
      padding: 20px;
      background-color: var(--bg-color);
      color: #333;
    }
    
    h1 {
      color: var(--primary-color);
      margin-bottom: 20px;
    }
    
    .control-panel {
      background-color: var(--chat-bg);
      padding: 15px;
      border-radius: var(--border-radius);
      box-shadow: 0 2px 5px rgba(0,0,0,0.1);
      margin-bottom: 20px;
    }
    
    .settings-group {
      display: grid;
      grid-template-columns: repeat(auto-fill, minmax(250px, 1fr));
      gap: 15px;
      margin-bottom: 15px;
    }
    
    label { 
      display: block; 
      margin-bottom: 5px;
      font-weight: 500;
    }
    
    select, input {
      width: 100%;
      padding: 8px;
      border: 1px solid #ddd;
      border-radius: 4px;
      background-color: white;
    }
    
    .button-group {
      display: flex;
      gap: 10px;
    }
    
    button { 
      background-color: var(--primary-color);
      color: white;
      border: none;
      padding: 10px 15px;
      border-radius: 4px;
      cursor: pointer;
      font-weight: 500;
      transition: background-color 0.2s;
    }
    
    button:hover {
      background-color: var(--secondary-color);
    }
    
    button.secondary {
      background-color: #f0f0f0;
      color: #333;
    }
    
    button.secondary:hover {
      background-color: #e0e0e0;
    }
    
    button.stop-button {
      background-color: #e74c3c;
      color: white;
      padding: 5px 10px;
      font-size: 0.8em;
      margin-left: 10px;
    }
    
    button.stop-button:hover {
      background-color: #c0392b;
    }
    
    #status {
      padding: 8px 15px;
      background-color: var(--primary-color);
      color: white;
      border-radius: 4px;
      display: inline-block;
      margin: 10px 0;
    }
    
    #chatLog { 
      background-color: var(--chat-bg);
      border-radius: var(--border-radius);
      padding: 1em; 
      height: 400px;
      overflow-y: auto; 
      margin-top: 1em;
      box-shadow: 0 2px 5px rgba(0,0,0,0.1);
    }
    
    .message {
      margin-bottom: 15px;
      max-width: 80%;
      padding: 10px 15px;
      border-radius: var(--border-radius);
      position: relative;
      line-height: 1.5;
    }
    
    .user-message {
      background-color: var(--user-bubble);
      margin-left: auto;
      border-bottom-right-radius: 0;
    }
    
    .bot-message {
      background-color: var(--bot-bubble);
      margin-right: auto;
      border-bottom-left-radius: 0;
    }
    
    .message-content {
      word-wrap: break-word;
    }
    
    .message-header {
      font-weight: bold;
      margin-bottom: 5px;
    }
    
    .controls-row {
      display: flex;
      justify-content: space-between;
      align-items: center;
      margin-top: 10px;
    }
    
    .threshold-slider {
      display: flex;
      align-items: center;
      gap: 10px;
    }
    
    .threshold-slider input[type="range"] {
      flex-grow: 1;
    }
    
    .threshold-value {
      min-width: 40px;
    }
    
    /* Debug panel */
    .debug-panel {
      margin-top: 20px;
      padding: 10px;
      background-color: #f8f8f8;
      border: 1px solid #ddd;
      border-radius: var(--border-radius);
      font-family: monospace;
    }
    
    @media (max-width: 768px) {
      .settings-group {
        grid-template-columns: 1fr;
      }
    }
  </style>
</head>
<body>
  <h1>Voice Chat Assistant</h1>
  
  <div class="control-panel">
    <div class="settings-group">
      <div>
        <label for="model">LLM Modell:</label>
        <select id="model"></select>
      </div>
      
      <div>
        <label for="voice">Stimme:</label>
        <select id="voice"></select>
      </div>
      
      <div>
        <label for="language">Sprache:</label>
        <select id="language"></select>
      </div>
      
      <div>
        <label for="asrMode">Transkription:</label>
        <select id="asrMode">
          <option value="whisper">Whisper (Server)</option>
          <option value="browser">Browser ASR</option>
        </select>
      </div>
    </div>
    
    <div class="controls-row">
      <div class="threshold-slider">
        <label for="silenceThresholdRange">Erkennungsschwelle:</label>
        <input type="range" id="silenceThresholdRange" min="0.005" max="0.1" step="0.001" value="0.02">
        <span id="thresholdValue" class="threshold-value">0.02</span>
      </div>
      
      <div class="threshold-slider">
        <label for="silenceSec">Stille-Schwelle (s):</label>
        <input type="range" id="silenceSecRange" min="0.5" max="5" step="0.1" value="2">
        <input type="number" id="silenceSec" min="0.5" max="10" step="0.1" value="2" style="width: 60px;"/>
      </div>
    </div>
    
    <div class="button-group">
      <div id="status">Bereit</div>
      <button id="stopBtn" class="stop-button">Aufnahme stoppen</button>
      <button id="clearBtn" class="secondary">Chat leeren</button>
      <button id="debugBtn" class="secondary">Debug-Modus</button>
    </div>
  </div>
  
  <div id="chatLog"></div>
  
  <div id="debugPanel" class="debug-panel" style="display: none;">
    <h3>Debug-Informationen</h3>
    <div id="debugOutput"></div>
  </div>
  <script>
    // UI Elements
    const status = document.getElementById('status');
    const stopBtn = document.getElementById('stopBtn');
    const clearBtn = document.getElementById('clearBtn');
    const debugBtn = document.getElementById('debugBtn');
    const chatLog = document.getElementById('chatLog');
    const modelSel = document.getElementById('model');
    const langSel = document.getElementById('language');
    const voiceSel = document.getElementById('voice');
    const silenceSecInput = document.getElementById('silenceSec');
    const silenceSecRange = document.getElementById('silenceSecRange');
    const silenceThresholdRange = document.getElementById('silenceThresholdRange');
    const thresholdValue = document.getElementById('thresholdValue');
    const asrMode = document.getElementById('asrMode');
    const debugPanel = document.getElementById('debugPanel');
    const debugOutput = document.getElementById('debugOutput');
    
    // Audio state
    let currentAudio = null;
    let currentUtterance = null;
    let silenceThreshold = parseFloat(silenceThresholdRange.value);
    let recording = false;
    
    // Initialize values
    thresholdValue.textContent = silenceThreshold.toFixed(3);
    
    // Global stop button stops any current audio playback
    stopBtn.addEventListener('click', () => {
      stopAllAudio();
      status.textContent = 'Gestoppt';
    });
    
    // Clear chat button
    clearBtn.addEventListener('click', () => {
      chatLog.innerHTML = '';
      status.textContent = 'Chat geleert';
    });
    
    // Debug button
    debugBtn.addEventListener('click', () => {
      debugPanel.style.display = debugPanel.style.display === 'none' ? 'block' : 'none';
      debugBtn.textContent = debugPanel.style.display === 'none' ? 'Debug-Modus' : 'Debug ausblenden';
    });
    
    // Sync range and number input for silence seconds
    silenceSecRange.addEventListener('input', () => {
      silenceSecInput.value = silenceSecRange.value;
    });
    
    silenceSecInput.addEventListener('input', () => {
      silenceSecRange.value = silenceSecInput.value;
    });
    
    // Update threshold value on slider change
    silenceThresholdRange.addEventListener('input', () => {
      silenceThreshold = parseFloat(silenceThresholdRange.value);
      thresholdValue.textContent = silenceThreshold.toFixed(3);
    });
    
    // Function to stop all audio playback
    function stopAllAudio() {
      if (currentAudio) {
        currentAudio.pause();
        URL.revokeObjectURL(currentAudio.src);
        currentAudio = null;
      }
      if (currentUtterance) {
        speechSynthesis.cancel();
        currentUtterance = null;
      }
    }
    
    // Function to stop specific audio
    function stopAudio(audio) {
      if (audio) {
        audio.pause();
        if (audio === currentAudio) {
          URL.revokeObjectURL(audio.src);
          currentAudio = null;
        }
      }
    }
    
    // Debug log
    function debugLog(message) {
      console.log(message);
      const logEntry = document.createElement('div');
      logEntry.textContent = `${new Date().toLocaleTimeString()}: ${message}`;
      debugOutput.appendChild(logEntry);
      
      // Keep only last 100 entries
      while (debugOutput.children.length > 100) {
        debugOutput.removeChild(debugOutput.firstChild);
      }
      
      // Auto-scroll
      debugOutput.scrollTop = debugOutput.scrollHeight;
    }
    
    // Create a user message bubble
    function createUserMessage(text) {
      const messageDiv = document.createElement('div');
      messageDiv.className = 'message user-message';
      
      const header = document.createElement('div');
      header.className = 'message-header';
      header.textContent = 'Du';
      
      const content = document.createElement('div');
      content.className = 'message-content';
      content.textContent = text;
      
      messageDiv.appendChild(header);
      messageDiv.appendChild(content);
      chatLog.appendChild(messageDiv);
      chatLog.scrollTop = chatLog.scrollHeight;
      
      return messageDiv;
    }
    
    // Create a bot message bubble with optional audio
    function createBotMessage(text, model = modelSel.value) {
      const messageDiv = document.createElement('div');
      messageDiv.className = 'message bot-message';
      
      const header = document.createElement('div');
      header.className = 'message-header';
      header.textContent = `Assistant (${model})`;
      
      const content = document.createElement('div');
      content.className = 'message-content';
      content.textContent = text || '...';
      
      const controls = document.createElement('div');
      controls.className = 'message-controls';
      
      const stopButton = document.createElement('button');
      stopButton.className = 'stop-button';
      stopButton.textContent = 'Audio stoppen';
      stopButton.style.display = 'none';  // Hide initially until audio is playing
      
      messageDiv.appendChild(header);
      messageDiv.appendChild(content);
      messageDiv.appendChild(controls);
      controls.appendChild(stopButton);
      chatLog.appendChild(messageDiv);
      chatLog.scrollTop = chatLog.scrollHeight;
      
      return { messageDiv, content, stopButton };
    }
    // Dynamically load available chat models from server
    async function loadModels() {
      modelSel.innerHTML = '';
      try {
        const res = await fetch('/api/models');
        if (!res.ok) throw new Error(`HTTP ${res.status}`);
        const models = await res.json();
        models.forEach(m => {
          const opt = document.createElement('option'); opt.value = m; opt.textContent = m;
          modelSel.appendChild(opt);
        });
      } catch (err) {
        console.error('Fehler beim Laden der Modelle:', err);
        ['gpt-3.5-turbo', 'gpt-4'].forEach(m => {
          const opt = document.createElement('option'); opt.value = m; opt.textContent = m;
          modelSel.appendChild(opt);
        });
      }
    }
    const loadPromise = loadModels();
    const currentModelEl = document.getElementById('currentModel');
    modelSel.addEventListener('change', () => { currentModelEl.textContent = modelSel.value; });
    loadPromise.then(() => { currentModelEl.textContent = modelSel.value; });

    // Populate browser voices and OpenAI TTS voices
    const openaiVoices = ['nova', 'shimmer', 'echo', 'onyx', 'fable', 'alloy', 'ash', 'sage', 'coral'];
    function populateVoices() {
      // Speech language dropdown
      const voices = speechSynthesis.getVoices();
      langSel.innerHTML = '';
      voiceSel.innerHTML = '';
      const languages = [...new Set(voices.map(v => v.lang))];
      languages.forEach(lang => {
        const opt = document.createElement('option'); opt.value = lang; opt.textContent = lang;
        langSel.appendChild(opt);
      });
      // OpenAI TTS voice options
      openaiVoices.forEach(v => {
        const opt = document.createElement('option');
        opt.value = v;
        opt.textContent = `OpenAI ${v.charAt(0).toUpperCase() + v.slice(1)}`;
        voiceSel.appendChild(opt);
      });
      // Browser-native voices
      voices.forEach(voice => {
        const opt = document.createElement('option');
        opt.value = voice.name;
        opt.textContent = `${voice.name} (${voice.lang})`;
        voiceSel.appendChild(opt);
      });
    }
    speechSynthesis.onvoiceschanged = populateVoices;
    populateVoices();

    // Helper to append chat messages
    function appendChat(data) {
      const userMessage = document.createElement('p');
      userMessage.innerHTML = `<strong>Du:</strong> ${data.prompt}`;
      chatLog.appendChild(userMessage);
      const assistantMessage = document.createElement('p');
      assistantMessage.innerHTML = `<strong>Assistant (${data.model}):</strong> ${data.response}`;
      chatLog.appendChild(assistantMessage);
      chatLog.scrollTop = chatLog.scrollHeight;
    }

    // Helper to speak response with TTS or SpeechSynthesis
    async function speakResponse(text, stopButton) {
      // Validate text input
      if (!text || text.trim().length === 0) {
        debugLog("Attempted to synthesize empty text");
        status.textContent = 'Kein Text zum Vorlesen';
        return;
      }

      // Abort any previous playback
      stopAllAudio();

      // Ensure text is properly trimmed
      text = text.trim();
      
      if (openaiVoices.includes(voiceSel.value)) {
        status.textContent = 'Synthetisiere Sprache...';
        try {
          debugLog(`Synthetisiere Text (${text.length} Zeichen) mit Stimme ${voiceSel.value}`);
          
          const resp2 = await fetch('/api/speech', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ Input: text, Voice: voiceSel.value })
          });
          
          if (!resp2.ok) {
            const errText = await resp2.text();
            debugLog(`Fehler bei der Sprachsynthese: ${resp2.status} ${errText}`);
            status.textContent = `Fehler bei der Sprachsynthese: ${resp2.status}`;
            return;
          }
          
          const audioBlob = await resp2.blob();
          debugLog(`Audiodaten empfangen: ${Math.round(audioBlob.size / 1024)} KB`);
          
          const audioUrl = URL.createObjectURL(audioBlob);
          const audio = new Audio(audioUrl);
          currentAudio = audio;
          
          // Configure stop button
          if (stopButton) {
            stopButton.style.display = 'inline-block';
            stopButton.onclick = () => {
              stopAudio(audio);
              stopButton.style.display = 'none';
              status.textContent = 'Audio gestoppt';
            };
          }
          
          // Play audio
          status.textContent = 'Spielt Audio...';
          
          await new Promise(resolve => {
            audio.onended = () => { 
              URL.revokeObjectURL(audioUrl); 
              currentAudio = null;
              if (stopButton) stopButton.style.display = 'none';
              status.textContent = 'Bereit';
              resolve();
            };
            
            audio.onerror = (e) => {
              debugLog(`Fehler bei der Audiowiedergabe: ${e.toString()}`);
              URL.revokeObjectURL(audioUrl);
              currentAudio = null;
              if (stopButton) stopButton.style.display = 'none';
              status.textContent = 'Fehler bei der Audiowiedergabe';
              resolve();
            };
            
            audio.play().catch(e => {
              debugLog(`Fehler beim Starten der Audiowiedergabe: ${e.toString()}`);
              URL.revokeObjectURL(audioUrl);
              currentAudio = null;
              if (stopButton) stopButton.style.display = 'none';
              status.textContent = 'Fehler beim Starten der Audiowiedergabe';
              resolve();
            });
          });
          
        } catch (error) {
          debugLog(`TTS-Fehler: ${error.toString()}`);
          status.textContent = `Fehler bei der Sprachsynthese`;
        }
      } else {
        // Browser Speech Synthesis
        status.textContent = 'Spricht...';
        try {
          debugLog(`Verwende Browser-SpeechSynthesis mit Stimme ${voiceSel.value}`);
          
          await new Promise(resolve => {
            const utter = new SpeechSynthesisUtterance(text);
            currentUtterance = utter;
            utter.lang = langSel.value;
            const selectedVoice = speechSynthesis.getVoices().find(v => v.name === voiceSel.value);
            if (selectedVoice) utter.voice = selectedVoice;
            
            // Configure stop button
            if (stopButton) {
              stopButton.style.display = 'inline-block';
              stopButton.onclick = () => {
                if (currentUtterance) {
                  speechSynthesis.cancel();
                  currentUtterance = null;
                }
                stopButton.style.display = 'none';
                status.textContent = 'Audio gestoppt';
                resolve();
              };
            }
            
            utter.onend = () => { 
              currentUtterance = null; 
              if (stopButton) stopButton.style.display = 'none';
              status.textContent = 'Bereit';
              resolve();
            };
            
            utter.onerror = (e) => { 
              debugLog(`SpeechSynthesis-Fehler: ${e.toString()}`);
              currentUtterance = null;
              if (stopButton) stopButton.style.display = 'none';
              status.textContent = 'Fehler bei der Sprachsynthese';
              resolve();
            };
            
            speechSynthesis.speak(utter);
          });
        } catch (error) {
          debugLog(`Browser-Sprachsynthese-Fehler: ${error.toString()}`);
          status.textContent = `Fehler bei der Browser-Sprachsynthese`;
        }
      }
    }
    

    if (asrMode.value === 'browser' && (window.SpeechRecognition || window.webkitSpeechRecognition)) {
      // Streaming ASR via Web Speech API
      (function() {
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        const recognition = new SpeechRecognition();
        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.lang = langSel.value;
        recognition.onstart = () => { status.textContent = 'Listening (ASR)...'; };
        recognition.onerror = (e) => { console.error('Speech recognition error', e); status.textContent = 'Error in recognition'; };
        recognition.onresult = async (event) => {
          let interimTranscript = '';
          let finalTranscript = '';
          for (let i = event.resultIndex; i < event.results.length; i++) {
            const result = event.results[i];
            const transcript = result[0].transcript;
            if (result.isFinal) finalTranscript += transcript;
            else interimTranscript += transcript;
          }
          if (interimTranscript) {
            status.textContent = interimTranscript;
          }
          if (finalTranscript) {
            status.textContent = 'Processing...';
            await sendChat(finalTranscript.trim());
            status.textContent = 'Listening (ASR)...';
          }
        };
        recognition.onend = () => recognition.start();
        recognition.start();

        async function sendChat(prompt) {
          try {
            status.textContent = 'Connecting...';
            const resp = await fetch('/api/chatStream', {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({ model: modelSel.value, prompt })
            });
            if (!resp.ok) { status.textContent = `Error: ${resp.status}`; return; }
            const reader = resp.body.getReader();
            const decoder = new TextDecoder();
            let buffer = '';
            let content = '';
            
            // Create proper message bubbles in the correct order
            createUserMessage(prompt);
            const { content: contentElem, stopButton } = createBotMessage('');
            while (true) {
              const { value, done } = await reader.read();
              if (done) break;
              buffer += decoder.decode(value, { stream: true });
              const parts = buffer.split('\n\n');
              buffer = parts.pop();
              for (const part of parts) {
                const lines = part.split('\n');
                let eventType = '';
                let dataLine = '';
                for (const line of lines) {
                  if (line.startsWith('event: ')) eventType = line.slice(7);
                  else if (line.startsWith('data: ')) dataLine = line.slice(6);
                }
                if (eventType === 'prompt') continue;
                if (dataLine) {
                  const obj = JSON.parse(dataLine);
                  if (obj.token !== undefined) {
                    // Token-by-token streaming (optimized)
                    content += obj.token;
                    // Update UI more efficiently for token streaming
                    requestAnimationFrame(() => {
                      contentElem.textContent = content;
                      chatLog.scrollTop = chatLog.scrollHeight;
                    });
                  } else if (obj.message !== undefined) {
                    content += obj.message;
                    contentElem.textContent = content;
                    chatLog.scrollTop = chatLog.scrollHeight;
                  } else if (obj.response !== undefined) {
                    content += obj.response;
                    contentElem.textContent = content;
                    chatLog.scrollTop = chatLog.scrollHeight;
                  }
                }
                if (eventType === 'done') {
                  await speakResponse(content, stopButton);
                }
              }
            }
          } catch (err) {
            console.error(err);
            status.textContent = 'Error in ASR chat';
          }
        }
      })();
    } else {
      if (asrMode.value === 'browser') {
        status.textContent = 'Browser ASR not supported, falling back to Whisper (server)';
      }
      // Continuous recording with silence detection
    (async () => {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const audioContext = new AudioContext();
      const source = audioContext.createMediaStreamSource(stream);
      const analyser = audioContext.createAnalyser();
      // Reduce FFT size for lower-latency voice activity detection
      analyser.fftSize = 1024;
      source.connect(analyser);
      const dataArray = new Uint8Array(analyser.fftSize);
      const recorder = new MediaRecorder(stream);
      let chunks = [];
      recorder.ondataavailable = e => chunks.push(e.data);
      recorder.onstop = async () => {
        status.textContent = 'Uploading...';
        const blob = new Blob(chunks, { type: 'audio/webm' });
        const fd = new FormData();
        fd.append('file', blob, 'audio.webm');
        fd.append('model', modelSel.value);
        fd.append('language', langSel.value);
        try {
          console.log("Uploading audio for processing...");
          status.textContent = 'Connecting...';
          const resp = await fetch('/api/processAudioStream', { method: 'POST', body: fd });
          
          if (!resp.ok) { 
            const errorText = await resp.text();
            console.error(`Server error: ${resp.status}, ${errorText}`);
            status.textContent = `Error: ${resp.status}`; 
            return; 
          }
          
          console.log("Connection established, processing response stream...");
          const reader = resp.body.getReader();
          const decoder = new TextDecoder();
          let buffer = '';
          let content = '';
          
          // We'll create the bot message bubble after we receive the user's prompt
          let contentElem = null;
          let stopButton = null;
          
          // Flag to track if we've received any tokens
          let receivedAnyTokens = false;
          
          // Parse SSE stream
          while (true) {
            const { value, done: doneReading } = await reader.read();
            if (doneReading) {
              console.log("Stream reading done");
              break;
            }
            
            const chunk = decoder.decode(value, { stream: true });
            console.log(`Received chunk: ${chunk.length} bytes`);
            buffer += chunk;
            
            const parts = buffer.split('\n\n');
            buffer = parts.pop();
            
            console.log(`Processing ${parts.length} SSE parts`);
            
            for (const part of parts) {
              const lines = part.split('\n');
              let eventType = '';
              let dataLine = '';
              
              for (const line of lines) {
                if (line.startsWith('event: ')) {
                  eventType = line.slice(7);
                  console.log(`Event type: ${eventType}`);
                }
                else if (line.startsWith('data: ')) {
                  dataLine = line.slice(6);
                }
              }
              
              if (eventType === 'prompt') {
                try {
                  const obj = JSON.parse(dataLine);
                  console.log(`Received prompt: "${obj.prompt}"`);
                  // Add user message first
                  createUserMessage(obj.prompt);
                  
                  // Now create bot message bubble (AFTER the user message)
                  const botMessage = createBotMessage('');
                  contentElem = botMessage.content;
                  stopButton = botMessage.stopButton;
                } catch (e) {
                  console.error(`Error parsing prompt data: ${e.message}`);
                }
              } else if (eventType === 'token') {
                try {
                  const obj = JSON.parse(dataLine);
                  if (obj.token !== undefined) {
                    receivedAnyTokens = true;
                    // Token-by-token streaming (optimized)
                    content += obj.token;
                    
                    // Update UI more efficiently for token streaming
                    requestAnimationFrame(() => {
                      if (contentElem) {
                        contentElem.textContent = content;
                        chatLog.scrollTop = chatLog.scrollHeight;
                      }
                    });
                  }
                } catch (e) {
                  console.error(`Error parsing token data: ${e.message}`);
                  debugLog(`Error parsing token data: ${e.message}`);
                }
              } else if (!eventType || eventType === 'message') {
                try {
                  const obj = JSON.parse(dataLine);
                  debugLog("Received message data: " + JSON.stringify(obj));
                  
                  if (obj.token !== undefined) {
                    receivedAnyTokens = true;
                    // Token-by-token streaming (optimized)
                    content += obj.token;
                    // Update UI more efficiently for token streaming
                    requestAnimationFrame(() => {
                      if (contentElem) {
                        contentElem.textContent = content;
                        chatLog.scrollTop = chatLog.scrollHeight;
                      }
                    });
                  } else if (obj.message !== undefined) {
                    receivedAnyTokens = true;
                    content += obj.message;
                    if (contentElem) {
                      contentElem.textContent = content;
                      chatLog.scrollTop = chatLog.scrollHeight;
                    }
                  } else if (obj.response !== undefined) {
                    receivedAnyTokens = true;
                    content += obj.response;
                    if (contentElem) {
                      contentElem.textContent = content;
                      chatLog.scrollTop = chatLog.scrollHeight;
                    }
                  }
                } catch (e) {
                  console.error(`Error parsing message data: ${e.message}, raw data: ${dataLine}`);
                  debugLog(`Error parsing message data: ${e.message}, raw data: ${dataLine}`);
                }
              } else if (eventType === 'done') {
                debugLog(`Stream complete, received ${content.length} characters`);
                
                if (content && content.length > 0) {
                  // Create bot message if it doesn't exist yet (failsafe)
                  if (!contentElem) {
                    const botMessage = createBotMessage(content);
                    contentElem = botMessage.content;
                    stopButton = botMessage.stopButton;
                  }
                  
                  await speakResponse(content, stopButton);
                } else {
                  debugLog("Empty response content, nothing to speak");
                  // Show a helpful message
                  if (contentElem) {
                    contentElem.textContent = "Keine Antwort generiert. Bitte versuchen Sie es erneut.";
                  }
                }
                
                status.textContent = 'Zuhören...';
                status.style.fontWeight = 'normal';
                return;
              } else if (eventType === 'error') {
                try {
                  const obj = JSON.parse(dataLine);
                  console.error("Server error:", obj.error);
                  status.textContent = `Error: ${obj.error}`;
                } catch (e) {
                  console.error(`Error parsing error event: ${e.message}`);
                }
                return;
              }
            }
          }
          
          // If we reached end of stream without 'done' event
          debugLog("Stream ended without done event");
          if (receivedAnyTokens) {
            // Create bot message if it doesn't exist yet (failsafe)
            if (!contentElem) {
              const botMessage = createBotMessage(content);
              contentElem = botMessage.content;
              stopButton = botMessage.stopButton;
            }
            
            await speakResponse(content, stopButton);
          } else {
            debugLog("No tokens received in the response");
            if (contentElem) {
              contentElem.textContent = "Keine Antwort empfangen. Bitte versuchen Sie es erneut.";
            }
          }
          
          status.textContent = 'Zuhören...';
          status.style.fontWeight = 'normal';
        } catch (err) {
          console.error(err);
          status.textContent = 'Error in processing';
        }
        status.textContent = 'Listening...';
      };
      let speakingSegment = false;
      let silenceStart = null;
      status.textContent = 'Zuhören...';
      // Poll more frequently for quicker reaction (ms)
      setInterval(() => {
        analyser.getByteTimeDomainData(dataArray);
        let sumSquares = 0;
        for (let i = 0; i < dataArray.length; i++) {
          const v = (dataArray[i] - 128) / 128;
          sumSquares += v * v;
        }
        const rms = Math.sqrt(sumSquares / dataArray.length);
        
        // Debug output for audio levels
        if (debugPanel.style.display !== 'none') {
          // Add audio level to debug panel
          const levelBar = document.createElement('div');
          levelBar.style.width = `${Math.min(rms * 1000, 100)}%`;
          levelBar.style.height = '10px';
          levelBar.style.backgroundColor = rms > silenceThreshold ? '#4CAF50' : '#F44336';
          levelBar.style.marginBottom = '2px';
          debugOutput.appendChild(levelBar);
          
          // Keep only most recent bars
          while (debugOutput.children.length > 50) {
            debugOutput.removeChild(debugOutput.firstChild);
          }
          
          debugLog(`Audio level: ${rms.toFixed(4)}, Threshold: ${silenceThreshold.toFixed(4)}`);
        }
        
        if (rms > silenceThreshold) {
          if (!speakingSegment) {
            speakingSegment = true;
            chunks = [];
            recorder.start();
            status.textContent = 'Recording...';
            console.log("Recording started - audio level above threshold");
          }
          silenceStart = null;
        } else {
          if (speakingSegment) {
            if (!silenceStart) {
              silenceStart = Date.now();
              console.log("Silence detected, starting silence timer");
            }
            else if (Date.now() - silenceStart > parseFloat(silenceSecInput.value) * 1000) {
              speakingSegment = false;
              console.log(`Stopping recording after ${parseFloat(silenceSecInput.value)} seconds of silence`);
              
              // Force a more obvious visual feedback
              status.textContent = 'Processing...';
              status.style.fontWeight = 'bold';
              
              recorder.stop();
            }
          }
        }
      }, 50);
      
      // Add debug toggle button
      const debugButton = document.createElement('button');
      debugButton.textContent = 'Toggle Audio Debug';
      debugButton.style.marginTop = '10px';
      debugButton.onclick = () => {
        window._debugAudioLevels = !window._debugAudioLevels;
        debugButton.textContent = window._debugAudioLevels ? 'Disable Audio Debug' : 'Enable Audio Debug';
      };
      document.body.appendChild(debugButton);
    })();
    }
  </script>
</body>
</html>