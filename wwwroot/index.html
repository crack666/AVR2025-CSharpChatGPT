<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Voice Chat Assistant</title>
  <style>
    body { font-family: Arial, sans-serif; margin: 2em; }
    label { display: block; margin-top: 1em; }
    button { margin-top: 1em; padding: 0.5em 1em; }
    #chatLog { border: 1px solid #ccc; padding: 1em; max-height: 400px; overflow-y: auto; margin-top: 1em; }
  </style>
</head>
<body>
  <h1>Voice Chat Assistant</h1>
  <label>Model:
    <select id="model"></select>
  </label>
  <p>Aktuelles Modell: <span id="currentModel"></span></p>
  <label>Speech Language:
    <select id="language"></select>
  </label>
  <label>Voice:
    <select id="voice"></select>
  </label>
  <button id="record">Start Recording</button>
  <p id="status"></p>
  <div id="chatLog"></div>
  <script>
    let recorder, chunks = [];
    const recordBtn = document.getElementById('record');
    const status = document.getElementById('status');
    const chatLog = document.getElementById('chatLog');
    const modelSel = document.getElementById('model');
    const langSel = document.getElementById('language');
    const voiceSel = document.getElementById('voice');
    // Dynamically load available chat models from server
    async function loadModels() {
      modelSel.innerHTML = '';
      try {
        const res = await fetch('/api/models');
        if (!res.ok) throw new Error(`HTTP ${res.status}`);
        const models = await res.json();
        models.forEach(m => {
          const opt = document.createElement('option'); opt.value = m; opt.textContent = m;
          modelSel.appendChild(opt);
        });
      } catch (err) {
        console.error('Fehler beim Laden der Modelle:', err);
        ['gpt-3.5-turbo', 'gpt-4'].forEach(m => {
          const opt = document.createElement('option'); opt.value = m; opt.textContent = m;
          modelSel.appendChild(opt);
        });
      }
    }
    const loadPromise = loadModels();
    const currentModelEl = document.getElementById('currentModel');
    modelSel.addEventListener('change', () => { currentModelEl.textContent = modelSel.value; });
    loadPromise.then(() => { currentModelEl.textContent = modelSel.value; });

    // Populate browser voices and OpenAI TTS voices
    const openaiVoices = ['nova', 'shimmer', 'echo', 'onyx', 'fable', 'alloy', 'ash', 'sage', 'coral'];
    function populateVoices() {
      // Speech language dropdown
      const voices = speechSynthesis.getVoices();
      langSel.innerHTML = '';
      voiceSel.innerHTML = '';
      const languages = [...new Set(voices.map(v => v.lang))];
      languages.forEach(lang => {
        const opt = document.createElement('option'); opt.value = lang; opt.textContent = lang;
        langSel.appendChild(opt);
      });
      // OpenAI TTS voice options
      openaiVoices.forEach(v => {
        const opt = document.createElement('option');
        opt.value = v;
        opt.textContent = `OpenAI ${v.charAt(0).toUpperCase() + v.slice(1)}`;
        voiceSel.appendChild(opt);
      });
      // Browser-native voices
      voices.forEach(voice => {
        const opt = document.createElement('option');
        opt.value = voice.name;
        opt.textContent = `${voice.name} (${voice.lang})`;
        voiceSel.appendChild(opt);
      });
    }
    speechSynthesis.onvoiceschanged = populateVoices;
    populateVoices();

    recordBtn.onclick = () => {
      if (recorder && recorder.state === 'recording') {
        recorder.stop();
        recordBtn.textContent = 'Start Recording';
      } else {
        navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {
          recorder = new MediaRecorder(stream);
          chunks = [];
          recorder.ondataavailable = e => chunks.push(e.data);
          recorder.onstop = async () => {
            status.textContent = 'Uploading...';
            const blob = new Blob(chunks, { type: 'audio/webm' });
            const fd = new FormData();
            fd.append('file', blob, 'audio.webm');
            fd.append('model', modelSel.value);
            fd.append('language', langSel.value);
            const resp = await fetch('/api/processAudio', { method: 'POST', body: fd });
            if (!resp.ok) { status.textContent = 'Error processing audio'; return; }
            const data = await resp.json();
            console.log('processAudio response:', data, 'model selected:', modelSel.value);
            const userMessage = document.createElement('p');
            userMessage.innerHTML = `<strong>Du:</strong> ${data.prompt}`;
            chatLog.appendChild(userMessage);
            const assistantMessage = document.createElement('p');
            assistantMessage.innerHTML = `<strong>Assistant (${data.model}):</strong> ${data.response}`;
            chatLog.appendChild(assistantMessage);
            chatLog.scrollTop = chatLog.scrollHeight;
            // Speak response: use OpenAI TTS or browser SpeechSynthesis
            if (openaiVoices.includes(voiceSel.value)) {
              status.textContent = 'Synthesizing...';
              const resp2 = await fetch('/api/speech', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ Input: data.response, Voice: voiceSel.value })
              });
            if (!resp2.ok) {
              const errText = await resp2.text();
              status.textContent = `Error synthesizing speech: ${resp2.status} ${errText}`;
              return;
            }
              const audioBlob = await resp2.blob();
              const audioUrl = URL.createObjectURL(audioBlob);
              const audio = new Audio(audioUrl);
              audio.onended = () => { status.textContent = ''; URL.revokeObjectURL(audioUrl); };
              audio.play();
            } else {
              status.textContent = 'Speaking...';
              const utter = new SpeechSynthesisUtterance(data.response);
              utter.lang = langSel.value;
              const selectedVoice = speechSynthesis.getVoices().find(v => v.name === voiceSel.value);
              if (selectedVoice) utter.voice = selectedVoice;
              utter.onend = () => status.textContent = '';
              speechSynthesis.speak(utter);
            }
          };
          recorder.start();
          recordBtn.textContent = 'Stop Recording';
          status.textContent = 'Recording...';
        });
      }
    };
  </script>
</body>
</html>